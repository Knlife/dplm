# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - /datamodule: tokenized_protein
  - /callbacks: lm
  - /trainer: ddp_bf16

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# name of the run determines folder name in logs
project: "DPLM2_650m_Antibody"
name: "dplm2_650m_sabdab"

datamodule:
  data_dir: ${paths.data_dir}
  csv_file: SAbDab
  vocab_file: airkingbd/dplm2_650m
  struct_vocab_size: 8192
  max_tokens: 4000
  max_len: 1018

model:
  _target_: dplm2
  num_diffusion_timesteps: 500
  gradient_ckpt: false
  training_stage: continue_train_from_dplm2
  single_modality_ratio: 0.25
  folding_loss_ratio: 0.25
  inverse_folding_loss_ratio: 0.25
  joint_loss_ratio: 0.25
  independent_loss_ratio: 0.0
  lora:
    enable: true
    lora_rank: 16
    lora_dropout: 0.1
    lora_target_module: (esm.encoder.layer.[0-9]*.attention.(self.query|self.key|self.value|output.dense).*|esm.encoder.layer.[0-9]*.(intermediate|output).dense.*)
    modules_to_save: lm_head,esm.embeddings
  net:
    arch_type: esm
    name: airkingbd/dplm2_650m
    dropout: 0.1
    pretrain: true
    pretrained_model_name_or_path: /nas/data/jhkuang/projects/AntiDesign_related/dplm/weights/DPLM2_lightning
  self_mixup:
    enable: false
    with_original_loss: false
  tokenizer:
    vocab_file: ${datamodule.vocab_file}
    vocab_size: 33
  struct_tokenizer:
    exp_path: airkingbd/struct_tokenizer

task:
  _target_: lm/dplm2
  learning:
    watch_t1_t2_loss: false
    cal_constant_loss: true
    weight: linear
  criterion:
    _target_: byprot.modules.cross_entropy.StructAARDMCrossEntropyLoss
    label_smoothing: 0.0
    ignore_index: 1
  optimizer:
    type: adamw
    _partial_: true
    lr: ${train.lr}
    betas:
      - 0.9
      - 0.98
    weight_decay: 0.01 # 0.0001
  lr_scheduler:
    type: polynomial
    warmup_steps: 500
    total_steps: ${trainer.max_steps}
    lr: ${train.lr}
    lr_end: 1e-6  # 降低lr end以适配lr的降低
    warmup_init_lr: 1e-07
    power: 1

train:
  seed: 42
  lr: 5e-5  # 降低学习率，从1e-4降到5e-5（或3e-5）
  monitor: "val/loss"
  mode: "min"
  patience: 1000

trainer:
  min_epochs: 3  # 减少最小epoch，从10降到3
  max_epochs: 50  # 大幅减少最大epoch，从10000降到50
  gradient_clip_val: 0.5
  num_sanity_val_steps: 1
  reload_dataloaders_every_n_epochs: 1
  use_distributed_sampler: false
  max_steps: 20_000  # 减少训练步数，从100k降到20k
  accumulate_grad_batches: 1
  check_val_every_n_epoch: null
  val_check_interval: 200  # 更频繁验证，从500降到200
  enable_progress_bar: true
  num_nodes: 1
